{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRanPgdfdVzc7meTZvKDb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuu-eguci/flower-stuff-lab/blob/main/yuueguci/fine_tuning_with_17flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBgFLQ6hEnk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eade591-19c1-417d-dcaf-71d26de344a9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun 17 14:15:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    73W / 149W |   8558MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r36MTtu9KBrI",
        "outputId": "11d8b075-3405-45d8-bc44-1ec77e5fec6b"
      },
      "source": [
        "# Google Drive をマウントします。\n",
        "# NOTE: 左のトコをポチポチやってマウントすることも出来ますが、マウントすることを明示するほうが好みなのでしています。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uj4-4F1M1Vu"
      },
      "source": [
        "# 17flowers dataset を取得します。\n",
        "# NOTE: マイドライブに 17flowers.zip を置いてある必要があります。自分で用意してください。\n",
        "#       /content は一時領域なので、数時間ごとに消滅します。\n",
        "#       だからイチイチ、 unzip しています。\n",
        "!unzip \"/content/drive/MyDrive/datasets/17flowers.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hIdxV4tNhiP"
      },
      "source": [
        "# 学習用画像が格納されているフォルダです。\n",
        "TRAIN_DIR = '/content/train_images'\n",
        "# テスト用画像が格納されているフォルダです。\n",
        "TEST_DIR = '/content/test_images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmdlKkqXNdM_"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWszlD80NvHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987909dc-6add-4b10-c207-624853ba98d7"
      },
      "source": [
        "# VGG16 のデフォルトである 224x224 でインプットを定義します。\n",
        "# NOTE: <class 'keras.engine.keras_tensor.KerasTensor'>\n",
        "# NOTE: Tensor は\n",
        "#       > 線形的な量または線形的な幾何概念を一般化したもので、基底を選べば、多次元の配列として表現できるようなものである。\n",
        "#       > (Wikipedia より)\n",
        "#       です。(?)\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "# VGG16 をロードします。\n",
        "# が、今回はフル結合3層をつけずにロードしています。\n",
        "# NOTE: include_top=False がフル結合3層をつけないという指定です。\n",
        "#       VGG16 は畳み込み13層とフル結合3層の計16層から成ります。\n",
        "#       なので、いうなれば VGG13 になってるってこと。\n",
        "#       (これは理解しやすいからそう書いているだけで誤解なきよう。)\n",
        "# NOTE: <class 'keras.engine.functional.Functional'>\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "# 新たな層を追加しています。\n",
        "# この output っていうのが現在の最後の13層目のことです。\n",
        "# NOTE: <class 'keras.engine.keras_tensor.KerasTensor'>\n",
        "x = base_model.output\n",
        "\n",
        "# GlobalAveragePooling2D という層を足しています。(14層目)\n",
        "# NOTE: さっき VGG13 だったのが VGG14 になるってこと。\n",
        "#       (これは理解しやすいからそう書いているだけなので他所で言わないように。)\n",
        "# NOTE: Dense は時間がかかるが GlobalAveragePooling は高速だという話です。\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Dense という層を足しています。(15層目)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# ここが自分の追加したい層。(16層目)\n",
        "y = Dense(17, activation='softmax')(x)\n",
        "\n",
        "# 完成したこれが層のかたまり。\n",
        "# NOTE: x とか y とかって変数名を使っているのは、このモデルの構築手順は数式で表せる(らしい)からです。\n",
        "#       こんな感じに。こういうのって数式って言うの? 方程式じゃなくて?\n",
        "#       y = Dense(Dense(GlobalAveragePooling2D(x)))\n",
        "# NOTE: <class 'keras.engine.functional.Functional'>\n",
        "model = Model(inputs=base_model.input, outputs=y)\n",
        "\n",
        "# 構築した改造 VGG16 を閲覧します。\n",
        "# VGG1 6の構造に加え、最後に層が追加されている事がわかります。\n",
        "# NOTE: こういうのが増えてる\n",
        "#       dense_1 (Dense)              (None, 17)                17425\n",
        "#       たぶん17ってのが Dense(17... で追加した層だろう。\n",
        "model.summary()\n",
        "\n",
        "# VGG16 の全層の重みを固定しています。\n",
        "# VGG16 側の層の重みは学習時に変更されません。\n",
        "# base_model は最初に用意した13層のこと。\n",
        "# これはもう学習終わってんのだから(imagenet で)、 train する必要なしです。\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# モデルを作っただけだと線形の結果しか出ません。\n",
        "# y = a * b * c * x みたいなものだからです。\n",
        "# 係数を自分で変更させるように……\n",
        "model.compile(\n",
        "    optimizer=SGD(\n",
        "        # NOTE: サンプルコードでは lr になっていたが、\n",
        "        #       UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
        "        #       が出るので learning_rate へ変更しました。\n",
        "        learning_rate=0.0001,\n",
        "        momentum=0.9,\n",
        "    ),\n",
        "    # 右辺と左辺の差を小さくするためのもの。微分です。\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Training に使う画像を生成する ImageDataGenerator を作ります。\n",
        "# NOTE: ImageDataGenerator は与えた画像をいじり、 training に使う画像パターンを増やします。\n",
        "#       https://keras.io/ja/preprocessing/image/\n",
        "# NOTE: <class 'keras.preprocessing.image.ImageDataGenerator'>\n",
        "image_data_generator_to_train = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        ")\n",
        "\n",
        "# 予測? 類推? 推測?(用語がわからん)テストに使う画像を生成する ImageDataGenerator を作ります。\n",
        "# NOTE: どうして小さくしているのかというと、モデルは小数点で学習するからです。\n",
        "#       どういうこと?\n",
        "image_data_generator_to_test = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        ")\n",
        "\n",
        "# ImageDataGenerator へ画像を与えます。\n",
        "# NOTE: <class 'keras.preprocessing.image.DirectoryIterator'>\n",
        "directory_iterator_for_training = image_data_generator_to_train.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "directory_iterator_for_test = image_data_generator_to_test.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# ここで学習を行います。なので時間かかります。\n",
        "# fit は学習のメソッドです。\n",
        "# NOTE: サンプルコードでは Model.fit_generator になっていたが、\n",
        "#       UserWarning: `Model.fit_generator` is deprecated and\n",
        "#                    will be removed in a future version.\n",
        "#                    Please use `Model.fit`, which supports generators.\n",
        "#       が出るため model.fit に変更しました。\n",
        "# NOTE: <class 'keras.callbacks.History'>\n",
        "history = model.fit(\n",
        "    directory_iterator_for_training,\n",
        "    # NOTE: 1190 はトレーニング用の枚数です。 70*17=1190\n",
        "    steps_per_epoch=1190 // 16,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_data=directory_iterator_for_test,\n",
        "    # NOTE: 170 はテスト用の枚数です。 10*17=170\n",
        "    validation_steps=170 // 16,\n",
        ")\n",
        "print(type(history))\n",
        "\n",
        "# 保存したものを予測にしか使わないなら include_optimizer=False を設定しておくと、サイズが半分以下になるそうだ。\n",
        "# NOTE: 保存したファイルを利用するのは別ファイルです。\n",
        "model.save('17flowers.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 17)                17425     \n",
            "=================================================================\n",
            "Total params: 15,257,425\n",
            "Trainable params: 15,257,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Found 1190 images belonging to 17 classes.\n",
            "Found 170 images belonging to 17 classes.\n",
            "Epoch 1/50\n",
            "74/74 [==============================] - 73s 351ms/step - loss: 2.8673 - accuracy: 0.1041 - val_loss: 2.8245 - val_accuracy: 0.1125\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 23s 309ms/step - loss: 2.8171 - accuracy: 0.1050 - val_loss: 2.7884 - val_accuracy: 0.1937\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.7875 - accuracy: 0.1376 - val_loss: 2.7735 - val_accuracy: 0.1750\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.7712 - accuracy: 0.1947 - val_loss: 2.7586 - val_accuracy: 0.2062\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.7506 - accuracy: 0.2456 - val_loss: 2.7443 - val_accuracy: 0.2125\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.7367 - accuracy: 0.2429 - val_loss: 2.7251 - val_accuracy: 0.2500\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.7227 - accuracy: 0.2773 - val_loss: 2.7187 - val_accuracy: 0.3000\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.7079 - accuracy: 0.2693 - val_loss: 2.7022 - val_accuracy: 0.3000\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 22s 303ms/step - loss: 2.6954 - accuracy: 0.3319 - val_loss: 2.6870 - val_accuracy: 0.3562\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.6831 - accuracy: 0.3450 - val_loss: 2.6786 - val_accuracy: 0.3938\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.6746 - accuracy: 0.3785 - val_loss: 2.6651 - val_accuracy: 0.3688\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.6604 - accuracy: 0.3828 - val_loss: 2.6516 - val_accuracy: 0.3688\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.6493 - accuracy: 0.3858 - val_loss: 2.6459 - val_accuracy: 0.3812\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 23s 304ms/step - loss: 2.6329 - accuracy: 0.3911 - val_loss: 2.6323 - val_accuracy: 0.3750\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.6176 - accuracy: 0.4344 - val_loss: 2.6224 - val_accuracy: 0.3812\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 23s 303ms/step - loss: 2.6030 - accuracy: 0.4670 - val_loss: 2.6103 - val_accuracy: 0.3625\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.5957 - accuracy: 0.4478 - val_loss: 2.5999 - val_accuracy: 0.3750\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.5927 - accuracy: 0.4535 - val_loss: 2.5862 - val_accuracy: 0.4062\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.5724 - accuracy: 0.4879 - val_loss: 2.5767 - val_accuracy: 0.4375\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.5734 - accuracy: 0.5139 - val_loss: 2.5708 - val_accuracy: 0.4375\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 22s 303ms/step - loss: 2.5511 - accuracy: 0.4862 - val_loss: 2.5492 - val_accuracy: 0.4375\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.5463 - accuracy: 0.4693 - val_loss: 2.5440 - val_accuracy: 0.4375\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.5202 - accuracy: 0.5205 - val_loss: 2.5262 - val_accuracy: 0.4875\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.5270 - accuracy: 0.4718 - val_loss: 2.5200 - val_accuracy: 0.4938\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.5077 - accuracy: 0.5004 - val_loss: 2.5045 - val_accuracy: 0.4688\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 2.4870 - accuracy: 0.5132 - val_loss: 2.4989 - val_accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.4862 - accuracy: 0.5481 - val_loss: 2.4784 - val_accuracy: 0.5188\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.4909 - accuracy: 0.5287 - val_loss: 2.4769 - val_accuracy: 0.4812\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 22s 299ms/step - loss: 2.4513 - accuracy: 0.5347 - val_loss: 2.4526 - val_accuracy: 0.5312\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.4531 - accuracy: 0.5273 - val_loss: 2.4490 - val_accuracy: 0.4750\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 22s 294ms/step - loss: 2.4336 - accuracy: 0.5770 - val_loss: 2.4338 - val_accuracy: 0.5562\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 22s 296ms/step - loss: 2.4332 - accuracy: 0.5454 - val_loss: 2.4222 - val_accuracy: 0.5562\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 22s 294ms/step - loss: 2.4081 - accuracy: 0.5821 - val_loss: 2.4193 - val_accuracy: 0.5375\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 22s 294ms/step - loss: 2.3994 - accuracy: 0.5707 - val_loss: 2.4078 - val_accuracy: 0.5375\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 2.3968 - accuracy: 0.5728 - val_loss: 2.3983 - val_accuracy: 0.5500\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.3795 - accuracy: 0.6079 - val_loss: 2.3882 - val_accuracy: 0.5250\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 22s 299ms/step - loss: 2.3686 - accuracy: 0.5842 - val_loss: 2.3796 - val_accuracy: 0.5375\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 22s 299ms/step - loss: 2.3658 - accuracy: 0.5482 - val_loss: 2.3613 - val_accuracy: 0.5500\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 22s 303ms/step - loss: 2.3793 - accuracy: 0.5261 - val_loss: 2.3525 - val_accuracy: 0.5312\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.3522 - accuracy: 0.5601 - val_loss: 2.3377 - val_accuracy: 0.5562\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 2.3290 - accuracy: 0.5804 - val_loss: 2.3363 - val_accuracy: 0.5562\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.3062 - accuracy: 0.5652 - val_loss: 2.3147 - val_accuracy: 0.5750\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 22s 301ms/step - loss: 2.3227 - accuracy: 0.5741 - val_loss: 2.3125 - val_accuracy: 0.5813\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.3002 - accuracy: 0.5672 - val_loss: 2.2912 - val_accuracy: 0.5562\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 23s 313ms/step - loss: 2.2845 - accuracy: 0.5777 - val_loss: 2.3047 - val_accuracy: 0.5250\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.2708 - accuracy: 0.5858 - val_loss: 2.2796 - val_accuracy: 0.5688\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 24s 321ms/step - loss: 2.2801 - accuracy: 0.5804 - val_loss: 2.2809 - val_accuracy: 0.5562\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.2562 - accuracy: 0.5806 - val_loss: 2.2581 - val_accuracy: 0.5875\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 23s 305ms/step - loss: 2.2425 - accuracy: 0.6046 - val_loss: 2.2538 - val_accuracy: 0.5750\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.2324 - accuracy: 0.5986 - val_loss: 2.2306 - val_accuracy: 0.5750\n",
            "<class 'keras.callbacks.History'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjsy7EcuWCrK"
      },
      "source": [
        "はやい！"
      ]
    }
  ]
}