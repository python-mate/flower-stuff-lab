{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_fitting.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yuu-eguci/flower-stuff-lab/blob/main/yuueguci/sample.ipynb",
      "authorship_tag": "ABX9TyPoRqHCus28Vnw5dCQxbhMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuu-eguci/flower-stuff-lab/blob/main/yuueguci/mnist_fitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBgFLQ6hEnk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940091e0-bf88-4a15-f0d1-2cfc0a125cba"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 27 03:44:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    29W /  70W |    990MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r36MTtu9KBrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3eb6cc7-5943-4a32-8077-d814a12661e2"
      },
      "source": [
        "# Google Drive をマウントします。\n",
        "# NOTE: 左のトコをポチポチやってマウントすることも出来ますが(というかそのほうがラク)\n",
        "# マウントすることを明示するほうが好みなのでしています。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMO_qgOjb3wu",
        "outputId": "85d59a16-d332-4dc5-aa4c-44b89231b8e2"
      },
      "source": [
        "# Keras のバージョンが結構重要な感あります。確認しておきます。\n",
        "!pip list | grep Keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras                         2.4.3              \n",
            "Keras-Preprocessing           1.1.2              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTmUDFLT3o4X"
      },
      "source": [
        "# NOTE: Colaboratory で module imported but unused とか出す方法あるのかな?\n",
        "# NOTE: この内容なら、 Colab では pip install 不要です。\n",
        "import os\n",
        "import time\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "# これはサンプルにはない。\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1f38X1J0kfd"
      },
      "source": [
        "class MNISTDataset():\n",
        "    \"\"\"MNIST dataset をクラスとして定義しています。\n",
        "    NOTE: image_shape とか、グローバルスコープで定数で定義するのイヤやん?\n",
        "    NOTE: インスタンス変数が変わることって無いと思うから、 static class にすべきじゃない?\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # MNIST は 28x28x1(グレースケール)のデータセットです。\n",
        "        self.image_shape = (28, 28, 1)\n",
        "        # クラス数は当然 0~9 の10個です。\n",
        "        self.num_classes = 10\n",
        "\n",
        "    def get_batch(self):\n",
        "\n",
        "        # NOTE: このメソッド名はサンプルママです。\n",
        "        #       強化学習の方式をオンライン学習といい、既存データセットから学習することをバッチ学習という。\n",
        "        #       「バッチ学習」用のデータだから batch なのかな。\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "        # preprocess により 0~1 の値に変換します。\n",
        "        # label_data(正解データ)は one-hot ベクトルへ変換します。\n",
        "        # NOTE: one-hot ベクトルは、ラベルの数(10)と等しい数のベクトルです。\n",
        "        # NOTE: ここはよくわかっていない。\n",
        "        x_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
        "        y_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
        "                           [y_train, y_test]]\n",
        "\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "    def preprocess(self, data, label_data=False):\n",
        "\n",
        "        if label_data:\n",
        "            # convert class vectors to binary class matrices\n",
        "            data = to_categorical(data, self.num_classes)\n",
        "        else:\n",
        "            data = data.astype('float32')\n",
        "            data /= 255  # convert the value to 0~1 scale\n",
        "            shape = (data.shape[0],) + self.image_shape  # add dataset length\n",
        "            data = data.reshape(shape)\n",
        "\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O64hcMXvs4OF"
      },
      "source": [
        "def lenet(input_shape, num_classes):\n",
        "    \"\"\"LeNet を定義します。\n",
        "    NOTE: LeNet は最初期の CNN です。\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # 畳み込み層を追加します。\n",
        "    # NOTE: 畳み込む領域5x5、フィルタ20枚、特徴マップのサイズは入力と同じ、\n",
        "    #       活性化関数 ReLU です。\n",
        "    # NOTE: input_shape を指定する必要があります。入力を受け取る最初の層なので。\n",
        "    # NOTE: 入力が28x28の画像なら、出力は28x28x20です。\n",
        "    model.add(Conv2D(\n",
        "        20,\n",
        "        kernel_size=5,\n",
        "        padding='same',\n",
        "        input_shape=input_shape,\n",
        "        activation='relu',\n",
        "    ))\n",
        "    # 畳み込み層にはプーリング層を追加。\n",
        "    # NOTE: 2x2の領域ごとに圧縮するので、上の Conv2D とあわせて\n",
        "    #       特徴マップは14x14x20になります。\n",
        "    model.add(MaxPooling2D(\n",
        "        pool_size=(2, 2)\n",
        "    ))\n",
        "\n",
        "    # 畳み込み層追加です。\n",
        "    # NOTE: 最初の Conv2D よりもフィルタが多いです。\n",
        "    #       深い層ほどフィルタを増やすことは、 CNN における一般的なテクです。\n",
        "    # NOTE: 入力は14x14x20の特徴マップです(↑でコメントした条件の場合)。\n",
        "    #       padding=same なので出力も 14x14x50 です。\n",
        "    model.add(Conv2D(\n",
        "        50,\n",
        "        kernel_size=5,\n",
        "        padding='same',\n",
        "        activation='relu')\n",
        "    )\n",
        "    # プーリング層追加です。\n",
        "    # NOTE: 更に小さく、7x7x50になります。\n",
        "    model.add(MaxPooling2D(\n",
        "        pool_size=(2, 2)\n",
        "    ))\n",
        "\n",
        "    # 特徴マップを全結合層と接続できるようにします。\n",
        "    # NOTE: 特徴マップ->ベクトルの変換らしい。\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # 全結合層です。サイズ500のベクトルを出力します。\n",
        "    model.add(Dense(\n",
        "        500,\n",
        "        activation='relu',\n",
        "    ))\n",
        "    # 分類クラスぶんのベクトルを出力します。\n",
        "    model.add(Dense(\n",
        "        num_classes,\n",
        "    ))\n",
        "\n",
        "    # 活性化関数 softmax により、値を 0~1 の確率値へ変換します。\n",
        "    # XXX: 全結合層がクラスぶんの値を出力するかと思ったが、そういうわけではなかったか。\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5Zlk7hW6KOi"
      },
      "source": [
        "class Trainer():\n",
        "    \"\"\"Fitting を行うクラスです。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, loss, optimizer):\n",
        "\n",
        "        self._target = model\n",
        "        self._target.compile(\n",
        "            loss=loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'],\n",
        "        )\n",
        "        self.verbose = 1\n",
        "        self.log_dir = '/content/drive/MyDrive/TensorBoardLogs/mnist_fitting'\n",
        "        self.hdf5_file_name = '/content/drive/MyDrive/hdf5/mnist_fitting.hdf5'\n",
        "\n",
        "    def train(self, x_train, y_train, batch_size, epochs, validation_split):\n",
        "\n",
        "        if os.path.exists(self.log_dir):\n",
        "            import shutil\n",
        "            shutil.rmtree(self.log_dir)  # remove previous execution\n",
        "        os.mkdir(self.log_dir)\n",
        "\n",
        "        self._target.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=[\n",
        "                TensorBoard(log_dir=self.log_dir),\n",
        "                ModelCheckpoint(self.hdf5_file_name, save_best_only=True),\n",
        "            ],\n",
        "            verbose=self.verbose\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCDesMeYPxSu",
        "outputId": "2f725d44-a325-4c22-dfd0-24746c4e6065"
      },
      "source": [
        "# MNIST を読み込みます。\n",
        "mnist_dataset = MNISTDataset()\n",
        "\n",
        "# LeNet モデルを作成します。\n",
        "lenet_model = lenet(\n",
        "    mnist_dataset.image_shape,\n",
        "    mnist_dataset.num_classes,\n",
        ")\n",
        "\n",
        "# MNIST からデータセットを取得します。\n",
        "x_train, y_train, x_test, y_test = mnist_dataset.get_batch()\n",
        "\n",
        "# Trainer にデータセットを渡します。\n",
        "trainer = Trainer(\n",
        "    lenet_model,\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(),\n",
        ")\n",
        "\n",
        "# Fitting します。\n",
        "# TODO: 毎回学習するのは非常にクソ面倒でいらっしゃいますので保存をしたいですね?\n",
        "start = time.time()\n",
        "trainer.train(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=12,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "print(f'Duration until fitting done: {time.time() - start} sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 0.4278 - accuracy: 0.8685 - val_loss: 0.0693 - val_accuracy: 0.9786\n",
            "Epoch 2/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0479 - val_accuracy: 0.9860\n",
            "Epoch 3/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.0449 - val_accuracy: 0.9858\n",
            "Epoch 4/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0410 - val_accuracy: 0.9887\n",
            "Epoch 5/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0403 - val_accuracy: 0.9877\n",
            "Epoch 6/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.0427 - val_accuracy: 0.9893\n",
            "Epoch 7/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0509 - val_accuracy: 0.9882\n",
            "Epoch 8/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0399 - val_accuracy: 0.9905\n",
            "Epoch 9/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0374 - val_accuracy: 0.9909\n",
            "Epoch 10/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0407 - val_accuracy: 0.9904\n",
            "Epoch 11/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0388 - val_accuracy: 0.9911\n",
            "Epoch 12/12\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0410 - val_accuracy: 0.9918\n",
            "Duration until fitting done: 29.05393958091736 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXLxTd94bwDe",
        "outputId": "4af006d1-dbe4-49b1-ba92-98d0427648df"
      },
      "source": [
        "# 結果を閲覧します。\n",
        "score = lenet_model.evaluate(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    verbose=0,\n",
        ")\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.03513319045305252\n",
            "Test accuracy: 0.9914000034332275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqlEfqsFdMGe"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/TensorBoardLogs/mnist_fitting"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}