{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1syHXpqnvDWHR4QREJJuO16uQQoXybUYq",
      "authorship_tag": "ABX9TyP3sgRAU8snGoUrg9fp7cYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuu-eguci/flower-stuff-lab/blob/main/goodluckpenpen/sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ1a90xtqbvb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZdLuQTAX5SQ",
        "outputId": "8161d416-64f4-4a44-8bbd-28494e673fbd"
      },
      "source": [
        "# Google Drive をマウントします。\n",
        "# NOTE: 左のトコをポチポチやってマウントすることも出来ますが、マウントすることを明示するほうが好みなのでしています。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRLUdJXesE2Y"
      },
      "source": [
        "# 17flowers dataset を取得します。\n",
        "# NOTE: マイドライブに 17flowers.zip を置いてある必要があります。自分で用意してください。\n",
        "#       /content は一時領域なので、数時間ごとに消滅します。\n",
        "#       だからイチイチ、 unzip しています。\n",
        "!unzip \"/content/drive/MyDrive/datasets/17flowers.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-rKPiPDsd3A"
      },
      "source": [
        "# 学習用画像が格納されているフォルダです。\n",
        "TRAIN_DIR = '/content/17flowers/train_images'\n",
        "# テスト用画像が格納されているフォルダです。\n",
        "TEST_DIR = '/content/17flowers/test_images'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryHE4jKyseFb"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_zcXY0seKM"
      },
      "source": [
        "# VGG16 のデフォルトである 224x224 でインプットを定義します。\n",
        "# NOTE: <class 'keras.engine.keras_tensor.KerasTensor'>\n",
        "# NOTE: Tensor は\n",
        "#       > 線形的な量または線形的な幾何概念を一般化したもので、基底を選べば、多次元の配列として表現できるようなものである。\n",
        "#       > (Wikipedia より)\n",
        "#       です。(?)\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "# VGG16 をロードします。\n",
        "# が、今回はフル結合3層をつけずにロードしています。\n",
        "# NOTE: include_top=False がフル結合3層をつけないという指定です。\n",
        "#       VGG16 は畳み込み13層とフル結合3層の計16層から成ります。\n",
        "#       なので、いうなれば VGG13 になってるってこと。\n",
        "#       (これは理解しやすいからそう書いているだけで誤解なきよう。)\n",
        "# NOTE: <class 'keras.engine.functional.Functional'>\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "# 新たな層を追加しています。\n",
        "# この output っていうのが現在の最後の13層目のことです。\n",
        "# NOTE: <class 'keras.engine.keras_tensor.KerasTensor'>\n",
        "x = base_model.output\n",
        "\n",
        "# GlobalAveragePooling2D という層を足しています。(14層目)\n",
        "# NOTE: さっき VGG13 だったのが VGG14 になるってこと。\n",
        "#       (これは理解しやすいからそう書いているだけなので他所で言わないように。)\n",
        "# NOTE: Dense は時間がかかるが GlobalAveragePooling は高速だという話です。\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Dense という層を足しています。(15層目)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "# ここが自分の追加したい層。(16層目)\n",
        "y = Dense(17, activation='softmax')(x)\n",
        "\n",
        "# 完成したこれが層のかたまり。\n",
        "# NOTE: x とか y とかって変数名を使っているのは、このモデルの構築手順は数式で表せる(らしい)からです。\n",
        "#       こんな感じに。こういうのって数式って言うの? 方程式じゃなくて?\n",
        "#       y = Dense(Dense(GlobalAveragePooling2D(x)))\n",
        "# NOTE: <class 'keras.engine.functional.Functional'>\n",
        "model = Model(inputs=base_model.input, outputs=y)\n",
        "\n",
        "# 構築した改造 VGG16 を閲覧します。\n",
        "# VGG1 6の構造に加え、最後に層が追加されている事がわかります。\n",
        "# NOTE: こういうのが増えてる\n",
        "#       dense_1 (Dense)              (None, 17)                17425\n",
        "#       たぶん17ってのが Dense(17... で追加した層だろう。\n",
        "model.summary()\n",
        "\n",
        "# VGG16 の全層の重みを固定しています。\n",
        "# VGG16 側の層の重みは学習時に変更されません。\n",
        "# base_model は最初に用意した13層のこと。\n",
        "# これはもう学習終わってんのだから(imagenet で)、 train する必要なしです。\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# モデルを作っただけだと線形の結果しか出ません。\n",
        "# y = a * b * c * x みたいなものだからです。\n",
        "# 係数を自分で変更させるように……\n",
        "model.compile(\n",
        "    optimizer=SGD(\n",
        "        # NOTE: サンプルコードでは lr になっていたが、\n",
        "        #       UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
        "        #       が出るので learning_rate へ変更しました。\n",
        "        learning_rate=0.0001,\n",
        "        momentum=0.9,\n",
        "    ),\n",
        "    # 右辺と左辺の差を小さくするためのもの。微分です。\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Training に使う画像を生成する ImageDataGenerator を作ります。\n",
        "# NOTE: ImageDataGenerator は与えた画像をいじり、 training に使う画像パターンを増やします。\n",
        "#       https://keras.io/ja/preprocessing/image/\n",
        "# NOTE: <class 'keras.preprocessing.image.ImageDataGenerator'>\n",
        "image_data_generator_to_train = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        ")\n",
        "\n",
        "# 予測? 類推? 推測?(用語がわからん)テストに使う画像を生成する ImageDataGenerator を作ります。\n",
        "# NOTE: どうして小さくしているのかというと、モデルは小数点で学習するからです。\n",
        "#       どういうこと?\n",
        "image_data_generator_to_test = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        ")\n",
        "\n",
        "# ImageDataGenerator へ画像を与えます。\n",
        "# NOTE: <class 'keras.preprocessing.image.DirectoryIterator'>\n",
        "directory_iterator_for_training = image_data_generator_to_train.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "directory_iterator_for_test = image_data_generator_to_test.flow_from_directory(\n",
        "    TEST_DIR,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# ここで学習を行います。なので時間かかります。\n",
        "# fit は学習のメソッドです。\n",
        "# NOTE: サンプルコードでは Model.fit_generator になっていたが、\n",
        "#       UserWarning: `Model.fit_generator` is deprecated and\n",
        "#                    will be removed in a future version.\n",
        "#                    Please use `Model.fit`, which supports generators.\n",
        "#       が出るため model.fit に変更しました。\n",
        "# NOTE: <class 'keras.callbacks.History'>\n",
        "history = model.fit(\n",
        "    directory_iterator_for_training,\n",
        "    # NOTE: 1190 はトレーニング用の枚数です。 70*17=1190\n",
        "    steps_per_epoch=1190 // 16,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=directory_iterator_for_test,\n",
        "    # NOTE: 170 はテスト用の枚数です。 10*17=170\n",
        "    validation_steps=170 // 16,\n",
        ")\n",
        "print(type(history))\n",
        "\n",
        "# 保存したものを予測にしか使わないなら include_optimizer=False を設定しておくと、サイズが半分以下になるそうだ。\n",
        "# NOTE: 保存したファイルを利用するのは別ファイルです。\n",
        "model.save('17flowers.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0TlommCseQT"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from keras.preprocessing import image\n",
        "import numpy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyuXOlp0seXA"
      },
      "source": [
        "CLASSES_FOR_17FLOWERS = [\n",
        "    'Tulip', 'Snowdrop', 'LilyValley', 'Bluebell', 'Crocus',\n",
        "    'Iris', 'Tigerlily', 'Daffodil', 'Fritillary', 'Sunflower',\n",
        "    'Daisy', 'ColtsFoot', 'Dandelion', 'Cowslip', 'Buttercup',\n",
        "    'Windflower', 'Pansy',\n",
        "]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Ypr9bbseZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48afb0c-bf56-4db5-ec55-f5d15e4038b3"
      },
      "source": [
        "# test_vgg16.py で行っているのと同じように、\n",
        "# 引数で与えられた画像を、予測へまわせる形式へ変換します。\n",
        "# <class 'PIL.Image.Image'>\n",
        "#       -> 3次元テンソル <class 'numpy.ndarray'>\n",
        "#       -> 4次元テンソル <class 'numpy.ndarray'>\n",
        "image_pil = image.load_img('/content/drive/MyDrive/keras-vgg16-lab/test-images/sunflower.jpg', target_size=(224, 224))\n",
        "image_array_3dim = image.img_to_array(image_pil)\n",
        "image_array_4dim = numpy.expand_dims(image_array_3dim, axis=0)\n",
        "\n",
        "# 学習時(fine_tuning_17flowers.py)において、 ImageDataGenerator の rescale で正規化したので同じ処理が必要。\n",
        "# XXX: ……らしいですよくわかんないです。\n",
        "# これを忘れると結果がおかしくなる。\n",
        "# XXX: ……らしいですよくわかんないです。\n",
        "# NOTE: どうおかしくなるのかわからなかったのでこれをやらないで試しました。\n",
        "#       やって sunflower.jpg 試した場合↓\n",
        "#           ('Cowslip', 0.14450616)\n",
        "#           ('Sunflower', 0.08813832)\n",
        "#           ('Tigerlily', 0.07421722)\n",
        "#       やらないで試した場合↓\n",
        "#           ('Cowslip', 0.9992175)\n",
        "#           ('Tigerlily', 0.0007754794)\n",
        "#           ('Buttercup', 6.109471e-06)\n",
        "image_array_4dim = image_array_4dim / 255.0\n",
        "\n",
        "# fine_tuning_17flowers.py で一番最初に作っているのと同じ、 VGG13(仮) + 自作3層 を用意します。\n",
        "# NOTE: Fine tuning 関連の記事ではよく Sequential が使われているけどまずこれでいく。\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "y = Dense(17, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=y)\n",
        "\n",
        "# Fine tuning ではこのあと重み固定(layer.trainable = False)とかをしています。\n",
        "# 今回は学習を行う必要がありません。 Weight file はすでにあるので。\n",
        "model.load_weights('/content/17flowers.hdf5')\n",
        "\n",
        "# NOTE: predict 前に model.compile する必要はありますか?\n",
        "#       試しました。\n",
        "#       やって sunflower.jpg 試した場合↓\n",
        "#           ('Cowslip', 0.14450616)\n",
        "#           ('Sunflower', 0.08813832)\n",
        "#           ('Tigerlily', 0.07421722)\n",
        "#       やらないで試した場合。あ、変わらないじゃん。やらないでいいみたい。\n",
        "#           ('Cowslip', 0.14450616)\n",
        "#           ('Sunflower', 0.08813832)\n",
        "#           ('Tigerlily', 0.07421722)\n",
        "\n",
        "# 予測を行います。\n",
        "# NOTE: test_vgg16 では\n",
        "#       predictions = vgg16.predict(preprocess_input(image_array_4dim))\n",
        "#       top_5_predictions = decode_predictions(predictions, top=5)[0]\n",
        "#       でしたね。どういうことやねん。\n",
        "# NOTE: test_vgg16.py では preprocess_input を使っていたのにどうしてこっちでは使わないのだろう?\n",
        "#       と思ったので使って試しました。\n",
        "#       使わず sunflower.jpg 試した場合↓\n",
        "#           ('Cowslip', 0.14450616)\n",
        "#           ('Sunflower', 0.08813832)\n",
        "#           ('Tigerlily', 0.07421722)\n",
        "#       使って試した場合。 Sunflower が消えた。\n",
        "#           ('Iris', 0.16075435)\n",
        "#           ('Tulip', 0.15425675)\n",
        "#           ('Fritillary', 0.13122706)\n",
        "prediction = model.predict(image_array_4dim)[0]\n",
        "top_indices = prediction.argsort()[-5:][::-1]\n",
        "result = [(CLASSES_FOR_17FLOWERS[i], prediction[i]) for i in top_indices]\n",
        "for x in result:\n",
        "    print(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Cowslip', 0.27655578)\n",
            "('Sunflower', 0.09722084)\n",
            "('Tigerlily', 0.09410678)\n",
            "('Pansy', 0.068630874)\n",
            "('Snowdrop', 0.062643126)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XOXfkjXsebV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}